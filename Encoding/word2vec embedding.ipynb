{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bebb3e-3b9a-44c9-a3ba-b739467c95fe",
   "metadata": {},
   "source": [
    "# import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5552eba-3724-402e-be4a-18fadff825e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62c17a2-b7bf-4799-b643-cb8dea1c8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Preprocessed_Final_dataset.csv',encoding='ISO-8859-1',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68693f6-bf0b-4034-8665-550dabe70e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41093</th>\n",
       "      <td>Indian culture is so backwards</td>\n",
       "      <td>N</td>\n",
       "      <td>indian culture is so backwards</td>\n",
       "      <td>['indian', 'culture', 'backwards']</td>\n",
       "      <td>indian culture backwards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41094</th>\n",
       "      <td>Women don't want equality, they just want to b...</td>\n",
       "      <td>N</td>\n",
       "      <td>women do not want equality they just want to b...</td>\n",
       "      <td>['woman', 'want', 'equality', 'want', 'charge']</td>\n",
       "      <td>woman want equality want charge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41095</th>\n",
       "      <td>fuck covid</td>\n",
       "      <td>P</td>\n",
       "      <td>fuck covid</td>\n",
       "      <td>['fuck', 'covid']</td>\n",
       "      <td>fuck covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41096</th>\n",
       "      <td>This computer is garbage</td>\n",
       "      <td>P</td>\n",
       "      <td>this computer is garbage</td>\n",
       "      <td>['computer', 'garbage']</td>\n",
       "      <td>computer garbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41097</th>\n",
       "      <td>The only good Muslim is a dead one</td>\n",
       "      <td>N</td>\n",
       "      <td>the only good muslim is a dead one</td>\n",
       "      <td>['good', 'muslim', 'dead', 'one']</td>\n",
       "      <td>good muslim dead one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment label  \\\n",
       "41093                     Indian culture is so backwards     N   \n",
       "41094  Women don't want equality, they just want to b...     N   \n",
       "41095                                         fuck covid     P   \n",
       "41096                           This computer is garbage     P   \n",
       "41097                 The only good Muslim is a dead one     N   \n",
       "\n",
       "                                              clean_text  \\\n",
       "41093                     indian culture is so backwards   \n",
       "41094  women do not want equality they just want to b...   \n",
       "41095                                         fuck covid   \n",
       "41096                           this computer is garbage   \n",
       "41097                 the only good muslim is a dead one   \n",
       "\n",
       "                                                tokens  \\\n",
       "41093               ['indian', 'culture', 'backwards']   \n",
       "41094  ['woman', 'want', 'equality', 'want', 'charge']   \n",
       "41095                                ['fuck', 'covid']   \n",
       "41096                          ['computer', 'garbage']   \n",
       "41097                ['good', 'muslim', 'dead', 'one']   \n",
       "\n",
       "                                  text  \n",
       "41093         indian culture backwards  \n",
       "41094  woman want equality want charge  \n",
       "41095                       fuck covid  \n",
       "41096                 computer garbage  \n",
       "41097             good muslim dead one  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432c627a-2d24-445f-bec6-dfcc6c7b8072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41093                 ['indian', 'culture', 'backwards']\n",
       "41094    ['woman', 'want', 'equality', 'want', 'charge']\n",
       "41095                                  ['fuck', 'covid']\n",
       "41096                            ['computer', 'garbage']\n",
       "41097                  ['good', 'muslim', 'dead', 'one']\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokens'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6506a85d-77ab-4c7f-9c17-a4d863936fbc",
   "metadata": {},
   "source": [
    "# Word2vec Embedding\n",
    "### Word2Vec is a neural network-based technique used to generate dense vector representations of words (word embeddings) by analyzing the context in which words appear in a large corpus. It captures semantic relationships between words, allowing similar words to have similar vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8dbd06-1ddc-4ea0-9fce-ef45aab9e661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  tokens  \\\n",
      "0                                 ['dalits', 'lowlives']   \n",
      "1                 ['gay', 'people', 'burden', 'society']   \n",
      "2                                    ['arab', 'welcome']   \n",
      "3      ['say', 'actually', 'eliminate', 'heebs', 'wis...   \n",
      "4                         ['bananas', 'black', 'people']   \n",
      "...                                                  ...   \n",
      "41093                 ['indian', 'culture', 'backwards']   \n",
      "41094    ['woman', 'want', 'equality', 'want', 'charge']   \n",
      "41095                                  ['fuck', 'covid']   \n",
      "41096                            ['computer', 'garbage']   \n",
      "41097                  ['good', 'muslim', 'dead', 'one']   \n",
      "\n",
      "                                                word2vec  \n",
      "0      [-0.4266507942652838, 0.2376399924131957, -0.4...  \n",
      "1      [-0.3708829174896604, 0.1886741215069043, -0.5...  \n",
      "2      [-0.44410782822064665, 0.2007582168045797, -0....  \n",
      "3      [-0.3864468749029091, 0.2195912663297481, -0.5...  \n",
      "4      [-0.4647836803769072, 0.23692237809300423, -0....  \n",
      "...                                                  ...  \n",
      "41093  [-0.4003428133095012, 0.2527630026726162, -0.4...  \n",
      "41094  [-0.3807463669911661, 0.2578567555372385, -0.5...  \n",
      "41095  [-0.36735586717943935, 0.23861637886832743, -0...  \n",
      "41096  [-0.35114243047554855, 0.22333083820083868, -0...  \n",
      "41097  [-0.356138098646294, 0.1929806750832182, -0.57...  \n",
      "\n",
      "[41098 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences=data['tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get the average Word2Vec vector for a list of tokens\n",
    "def get_average_word2vec(tokens, model):\n",
    "    vector_size = model.wv.vector_size\n",
    "    vec = np.zeros(vector_size)\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            vec += model.wv[token]\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "\n",
    "# Apply the Word2Vec embedding to the 'tokens' column and create a new column 'embedding'\n",
    "data['word2vec'] = data['tokens'].apply(lambda tokens: get_average_word2vec(tokens, model))\n",
    "\n",
    "# Print the DataFrame with the 'embedding' column\n",
    "print(data[['tokens', 'word2vec']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e1041e9-d366-4fb5-999e-c7ba816e3a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37088292  0.18867412 -0.52226355 -0.4618533   0.66761317  0.29138349\n",
      " -0.4844935   0.1283608   0.15404364  0.1625672  -0.32937421 -0.22990599\n",
      " -0.01976087 -0.50804704  0.57695737  0.04791758 -0.20498742  0.63101443\n",
      " -0.14344551 -0.60467383 -0.6726493  -0.11132524 -0.34027454 -0.65318591\n",
      " -0.17032868  0.05784599  0.16209572 -0.08375555 -0.30809036 -0.044493\n",
      " -0.02265684 -0.10323328 -0.77244696  0.64054363  0.13417346  0.02265263\n",
      " -0.10129337  0.68727328  0.30595777  0.68589826  0.2052327  -0.19899856\n",
      " -0.14508442  0.2011762   0.14341682 -0.11609395  0.15956573  0.08432091\n",
      " -0.1440511  -0.50340908  0.28256086 -0.03318373  0.01776271  0.05541772\n",
      " -0.35030209  0.01992745  0.14857223 -0.08174136  0.2519805  -0.24564511\n",
      "  0.03702207 -0.17680343  0.63455396 -0.04083006 -0.08729835  0.37009862\n",
      "  0.08139429 -0.35572975 -0.38042237 -0.14353437 -0.43685622  0.25735451\n",
      " -0.20158079  0.45579385  0.09272705  0.41283705 -0.02851004  0.20982927\n",
      "  0.07230102  0.64416328  0.3858545  -0.07270658  0.02395124 -0.23989182\n",
      "  0.14427446 -0.15817088 -0.32809208  0.29161449  0.57610178  0.15456964\n",
      " -0.15085336  0.535037    0.58194048 -0.22985443  0.50850057 -0.09626869\n",
      "  0.68141074  0.24493122  0.15832621 -0.27319337]\n"
     ]
    }
   ],
   "source": [
    "print(data['word2vec'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70d10b2a-cda1-436c-8c79-25fa931cf4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"word2vec_embedding.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37555df8-fdac-4c01-8779-31104f0ef785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
