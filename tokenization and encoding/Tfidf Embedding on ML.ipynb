{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85a46e2d-8363-450c-8ebe-76b333d98055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e84b6cf-38c1-4c65-b95c-48f5f51c0786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>N</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>['dalits', 'lowlives']</td>\n",
       "      <td>dalits lowlives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>N</td>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>['gay', 'people', 'burden', 'society']</td>\n",
       "      <td>gay people burden society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>N</td>\n",
       "      <td>arabs are not welcome</td>\n",
       "      <td>['arab', 'welcome']</td>\n",
       "      <td>arab welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>N</td>\n",
       "      <td>i am not saying we should actually eliminate h...</td>\n",
       "      <td>['say', 'actually', 'eliminate', 'heebs', 'wis...</td>\n",
       "      <td>say actually eliminate heebs wish naturally be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>N</td>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>['bananas', 'black', 'people']</td>\n",
       "      <td>bananas black people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment label  \\\n",
       "0                                dalits are lowlives     N   \n",
       "1             gay people are a burden to our society     N   \n",
       "2                              Arabs are not welcome     N   \n",
       "3  I'm not saying we should actually eliminate he...     N   \n",
       "4                       bananas are for black people     N   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                                dalits are lowlives   \n",
       "1             gay people are a burden to our society   \n",
       "2                              arabs are not welcome   \n",
       "3  i am not saying we should actually eliminate h...   \n",
       "4                       bananas are for black people   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                             ['dalits', 'lowlives']   \n",
       "1             ['gay', 'people', 'burden', 'society']   \n",
       "2                                ['arab', 'welcome']   \n",
       "3  ['say', 'actually', 'eliminate', 'heebs', 'wis...   \n",
       "4                     ['bananas', 'black', 'people']   \n",
       "\n",
       "                                                text  \n",
       "0                                    dalits lowlives  \n",
       "1                          gay people burden society  \n",
       "2                                       arab welcome  \n",
       "3  say actually eliminate heebs wish naturally be...  \n",
       "4                               bananas black people  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Preprocessed_Final_dataset.csv',encoding = 'latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a9d7f-2a27-4d48-9adb-5fbb58a07f67",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c69c90a-9e13-4a28-84e7-ddbe53f489c1",
   "metadata": {},
   "source": [
    "### TF-IDF is the importance of a term is inversely related to its frequency across documents.TF gives us information on how often a term appears in a document and IDF gives us information about the relative rarity of a term in the collection of documents. By multiplying these values together we can get our final TF-IDF value.The higher the TF-IDF score the more important or relevant the term is; as a term gets less relevant, its TF-IDF score will approach 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d84c2d5-2e5f-4738-9e38-eed6a2259bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in the 'clean_text' column\n",
    "data = data.dropna(subset=['text'])\n",
    "\n",
    "# Remove leading and trailing whitespace from the 'clean_text' column\n",
    "data['text'] = data['text'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2251e14f-bc6c-441e-9a63-ab4aae618c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text to TF-IDF features with a limit on max features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = tfidf_vectorizer.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d85199-a3ad-4d53-9979-114d2bbee875",
   "metadata": {},
   "source": [
    "# Label Encoding:\n",
    "\n",
    "### LabelEncoder converts the categorical label into numeric labels.This is useful for classification tasks where the target variable needs to be in numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad5854d-1d22-4167-a4bf-ec090775f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['label'])\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df['label'] = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab70d4c-63c4-4503-8891-89e15af309ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   able  absolute  absolutely  abuse  accept  accord  account  across  act  \\\n",
      "0   0.0       0.0         0.0    0.0     0.0     0.0      0.0     0.0  0.0   \n",
      "1   0.0       0.0         0.0    0.0     0.0     0.0      0.0     0.0  0.0   \n",
      "2   0.0       0.0         0.0    0.0     0.0     0.0      0.0     0.0  0.0   \n",
      "3   0.0       0.0         0.0    0.0     0.0     0.0      0.0     0.0  0.0   \n",
      "4   0.0       0.0         0.0    0.0     0.0     0.0      0.0     0.0  0.0   \n",
      "\n",
      "   action  ...  would  wow  write  wrong  yeah  year  yes  yet  young  label  \n",
      "0     0.0  ...    0.0  0.0    0.0    0.0   0.0   0.0  0.0  0.0    0.0      0  \n",
      "1     0.0  ...    0.0  0.0    0.0    0.0   0.0   0.0  0.0  0.0    0.0      0  \n",
      "2     0.0  ...    0.0  0.0    0.0    0.0   0.0   0.0  0.0  0.0    0.0      0  \n",
      "3     0.0  ...    0.0  0.0    0.0    0.0   0.0   0.0  0.0  0.0    0.0      0  \n",
      "4     0.0  ...    0.0  0.0    0.0    0.0   0.0   0.0  0.0  0.0    0.0      0  \n",
      "\n",
      "[5 rows x 1001 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6323b6-245f-47ca-94b5-700a495c5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('tf_idf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a323588-849a-4031-87a5-0c069c148d03",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a85a3efa-9da4-41bc-8e4f-80d39d5572d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6639493855700207\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.70      4466\n",
      "           1       0.64      0.61      0.62      3753\n",
      "\n",
      "    accuracy                           0.66      8219\n",
      "   macro avg       0.66      0.66      0.66      8219\n",
      "weighted avg       0.66      0.66      0.66      8219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4033a73-a281-4709-924e-ade965099379",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8856a21e-11ed-4d40-ab14-37d3efec5a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5584621000121669\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58      4466\n",
      "           1       0.52      0.55      0.53      3753\n",
      "\n",
      "    accuracy                           0.56      8219\n",
      "   macro avg       0.56      0.56      0.56      8219\n",
      "weighted avg       0.56      0.56      0.56      8219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear', max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9dbed7-69d4-4ebd-beb7-a7b34cf1d0ab",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705cf103-c7de-453e-b2b6-187adfbdfbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00952e4b-351e-4cb7-bb7e-10f2ba7891c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
