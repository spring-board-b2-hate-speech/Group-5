{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loda and processs data"
      ],
      "metadata": {
        "id": "8yQ6ahN9ovMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import re\n",
        "\n",
        "# Load the dataset (replace 'your_dataset.csv' with your actual dataset file)\n",
        "df = pd.read_csv('/content/dataset1_utf8.csv')\n",
        "\n",
        "# Count number of columns\n",
        "num_columns = df.shape[1]\n",
        "print(f\"Number of columns: {num_columns}\")\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to 'comment' column\n",
        "df['processed_comment'] = df['comment'].apply(preprocess_text)\n",
        "\n",
        "# Split dataset into features (X) and target (y)\n",
        "X = df['processed_comment']\n",
        "y = df['label']\n",
        "\n",
        "# Vectorize the text data (convert text to numerical features)\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust max_features as needed\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "# Print shape of data before sampling\n",
        "print(f\"Shape of data before sampling: {X_vec.shape}, {y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR0-G1F0ozzf",
        "outputId": "f911098f-b437-4a46-a046-85702d74317c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns: 3\n",
            "Shape of data before sampling: (41144, 1000), (41144,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle imbalance data"
      ],
      "metadata": {
        "id": "KBI03SQBo1Za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class weights based on their frequency (for cost-sensitive training)\n",
        "class_weights = {'N': 1, 'P': 2}  # Adjust as per your dataset distribution\n",
        "\n",
        "# Initialize the classifier with class weights for cost-sensitive training\n",
        "model_cs = RandomForestClassifier(class_weight=class_weights, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model_cs.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_cs = model_cs.predict(X_test)\n",
        "\n",
        "# Evaluate the model for cost-sensitive training\n",
        "print(\"Cost-Sensitive Training:\")\n",
        "print(classification_report(y_test, y_pred_cs))\n",
        "\n",
        "# Random Oversampling\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "\n",
        "# Apply random oversampling to the training data\n",
        "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Print shape of balanced data after oversampling\n",
        "print(f\"Shape of balanced data after random oversampling: {X_train_resampled.shape}, {y_train_resampled.shape}\")\n",
        "\n",
        "# Initialize the classifier for random oversampling\n",
        "model_ros = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Fit the model on the resampled data\n",
        "model_ros.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_ros = model_ros.predict(X_test)\n",
        "\n",
        "# Evaluate the model for random oversampling\n",
        "print(\"\\nRandom Oversampling:\")\n",
        "print(classification_report(y_test, y_pred_ros))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49kdCbClo7Yc",
        "outputId": "71d6176a-ad56-43c1-8b91-49d8c581277b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost-Sensitive Training:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.57      0.59      0.58      4375\n",
            "           O       0.00      0.00      0.00         4\n",
            "           P       0.51      0.49      0.50      3850\n",
            "\n",
            "    accuracy                           0.54      8229\n",
            "   macro avg       0.36      0.36      0.36      8229\n",
            "weighted avg       0.54      0.54      0.54      8229\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of balanced data after random oversampling: (53349, 1000), (53349,)\n",
            "\n",
            "Random Oversampling:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.53      0.55      0.54      4375\n",
            "           O       0.00      0.00      0.00         4\n",
            "           P       0.46      0.43      0.45      3850\n",
            "\n",
            "    accuracy                           0.50      8229\n",
            "   macro avg       0.33      0.33      0.33      8229\n",
            "weighted avg       0.49      0.50      0.49      8229\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and evaluate machine learning models"
      ],
      "metadata": {
        "id": "Kpn5ly5Io9Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import re\n",
        "\n",
        "# Load the dataset (replace 'your_dataset.csv' with your actual dataset file)\n",
        "df = pd.read_csv('/content/dataset1_utf8.csv')\n",
        "\n",
        "# Count number of columns\n",
        "num_columns = df.shape[1]\n",
        "print(f\"Number of columns: {num_columns}\")\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to 'comment' column\n",
        "df['processed_comment'] = df['comment'].apply(preprocess_text)\n",
        "\n",
        "# Split dataset into features (X) and target (y)\n",
        "X = df['processed_comment']\n",
        "y = df['label']\n",
        "\n",
        "# Vectorize the text data (convert text to numerical features)\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust max_features as needed\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "# Print shape of data before sampling\n",
        "print(f\"Shape of data before sampling: {X_vec.shape}, {y.shape}\")\n",
        "\n",
        "# Define class weights based on their frequency (for cost-sensitive training)\n",
        "class_weights = {'N': 1, 'P': 2}  # Adjust as per your dataset distribution\n",
        "\n",
        "# Initialize the classifier with class weights for cost-sensitive training\n",
        "model_cs = RandomForestClassifier(class_weight=class_weights, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model_cs.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_cs = model_cs.predict(X_test)\n",
        "\n",
        "# Evaluate the model for cost-sensitive training\n",
        "print(\"Cost-Sensitive Training:\")\n",
        "print(classification_report(y_test, y_pred_cs))\n",
        "\n",
        "# Random Oversampling\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "\n",
        "# Apply random oversampling to the training data\n",
        "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Print shape of balanced data after oversampling\n",
        "print(f\"Shape of balanced data after random oversampling: {X_train_resampled.shape}, {y_train_resampled.shape}\")\n",
        "\n",
        "# Initialize the classifier for random oversampling\n",
        "model_ros = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Fit the model on the resampled data\n",
        "model_ros.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_ros = model_ros.predict(X_test)\n",
        "\n",
        "# Evaluate the model for random oversampling\n",
        "print(\"\\nRandom Oversampling:\")\n",
        "print(classification_report(y_test, y_pred_ros))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0JySwLao9q7",
        "outputId": "526a9799-86e0-4872-bebe-a9da1322dcb7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns: 3\n",
            "Shape of data before sampling: (41144, 1000), (41144,)\n",
            "Cost-Sensitive Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.57      0.59      0.58      4375\n",
            "           O       0.00      0.00      0.00         4\n",
            "           P       0.51      0.49      0.50      3850\n",
            "\n",
            "    accuracy                           0.54      8229\n",
            "   macro avg       0.36      0.36      0.36      8229\n",
            "weighted avg       0.54      0.54      0.54      8229\n",
            "\n",
            "Shape of balanced data after random oversampling: (53349, 1000), (53349,)\n",
            "\n",
            "Random Oversampling:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.53      0.55      0.54      4375\n",
            "           O       0.00      0.00      0.00         4\n",
            "           P       0.46      0.43      0.45      3850\n",
            "\n",
            "    accuracy                           0.50      8229\n",
            "   macro avg       0.33      0.33      0.33      8229\n",
            "weighted avg       0.49      0.50      0.49      8229\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
