{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa08305-427c-4a72-a1f9-684de1ff8217",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93d565d-d5ab-4465-8a7e-179608bfe81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a9f1a-464f-4ffb-b18d-d866531756b1",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ee8bad-7dfa-4cd4-b17c-a98de490d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('hatspeech dataset.csv', encoding='ISO-8859-1')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a81ac81-b73d-4607-bec9-a1dbcb9f3940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41139</th>\n",
       "      <td>117100</td>\n",
       "      <td>Indian culture is so backwards</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41140</th>\n",
       "      <td>118100</td>\n",
       "      <td>Women don't want equality, they just want to b...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41141</th>\n",
       "      <td>119100</td>\n",
       "      <td>fuck covid</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41142</th>\n",
       "      <td>1205</td>\n",
       "      <td>This computer is garbage</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41143</th>\n",
       "      <td>121100</td>\n",
       "      <td>The only good Muslim is a dead one</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                            comment label\n",
       "0               1                                dalits are lowlives     N\n",
       "1               2             gay people are a burden to our society     N\n",
       "2               3                              Arabs are not welcome     N\n",
       "3               4  I'm not saying we should actually eliminate he...     N\n",
       "4               5                       bananas are for black people     N\n",
       "...           ...                                                ...   ...\n",
       "41139      117100                     Indian culture is so backwards     N\n",
       "41140      118100  Women don't want equality, they just want to b...     N\n",
       "41141      119100                                         fuck covid     P\n",
       "41142        1205                           This computer is garbage     P\n",
       "41143      121100                 The only good Muslim is a dead one     N\n",
       "\n",
       "[41144 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680121b-5cc4-4a97-b89d-55f0c7222bc5",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100bc39d-7201-408f-a4df-127c2bfc10a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                            comment label\n",
      "0           1                                dalits are lowlives     N\n",
      "1           2             gay people are a burden to our society     N\n",
      "2           3                              Arabs are not welcome     N\n",
      "3           4  I'm not saying we should actually eliminate he...     N\n",
      "4           5                       bananas are for black people     N\n"
     ]
    }
   ],
   "source": [
    "print(data.head())  # Check the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a06d0e08-8ecb-4fa1-bc2c-6d628573d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41144 entries, 0 to 41143\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  41144 non-null  int64 \n",
      " 1   comment     41144 non-null  object\n",
      " 2   label       41144 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 964.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())  # Get information about the dataset, like column names and data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99633d91-ff78-4a2f-ac18-95265e7fde96",
   "metadata": {},
   "source": [
    "# Checking the distribution of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a78c3d1-40c8-4944-ba17-17c23e32545a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "N    22158\n",
      "P    18950\n",
      "O       36\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['label'].value_counts())  # Check the distribution of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240cec9c-0c00-4584-b9af-06e1110cee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['label'] != 'O'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97914d50-bede-4449-853f-6a06effdcd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "N    22158\n",
      "P    18950\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654dfdd9-96b7-4521-819a-e00f2b999dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    False\n",
       "comment       False\n",
       "label         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526711de-38c8-4a07-a845-9befc0201b61",
   "metadata": {},
   "source": [
    "# Checking for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4ed9d8-7a6a-4357-9f16-89200bd798ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "#Find the number of duplicate rows\n",
    "num_duplicates = data.duplicated().sum()\n",
    "print(f'Number of duplicate rows: {num_duplicates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294a7c1-5e46-459c-a8f7-4586788b01b2",
   "metadata": {},
   "source": [
    "# Importing necessary nltk packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8626d76d-3ecf-499a-ac2e-8e9f04e4fe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maddi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maddi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maddi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ca472-3c80-4a41-ac43-297f7057f43c",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c72723bd-adce-4400-8326-c21814962e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatword_dictionary = {\n",
    "    'u': 'you',\n",
    "    'ur': 'your',\n",
    "    'r': 'are',\n",
    "    'y': 'why',\n",
    "    'b4': 'before',\n",
    "    'gr8': 'great',\n",
    "    'l8r': 'later',\n",
    "    'w8': 'wait',\n",
    "    'bff': 'best friend forever',\n",
    "    'brb': 'be right back',\n",
    "    'btw': 'by the way',\n",
    "    'cuz': 'because',\n",
    "    'idk': 'i do not know',\n",
    "    'ikr': 'i know right',\n",
    "    'imo': 'in my opinion',\n",
    "    'lmao': 'laughing my ass off',\n",
    "    'lol': 'laugh out loud',\n",
    "    'omg': 'oh my god',\n",
    "    'omw': 'on my way',\n",
    "    'pls': 'please',\n",
    "    'thx': 'thanks',\n",
    "    'ttyl': 'talk to you later',\n",
    "    'wth': 'what the hell',\n",
    "    'wyd': 'what you doing',\n",
    "    'smh': 'shaking my head'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d2d70f-f67e-413f-8cc7-dfed5fc4bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_dict = {\n",
    "    \"kinda\": \"kind of\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"gotta\": \"got to\",\n",
    "    \"ain't\": \"is not\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"idk\": \"I do not know\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"bbl\": \"be back later\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laughing out loud\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mustn't\": \"must not\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aef9b6b-eec6-478b-8253-f86f5458ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  text = text.lower()  # Convert text to lowercase\n",
    "  text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "  for chatword, full_form in chatword_dictionary.items():\n",
    "      text = re.sub(rf\"\\b{chatword}\\b\", full_form, text)\n",
    "  for slang, expanded in slang_dict.items():\n",
    "      text = re.sub(r'\\b' + re.escape(slang) + r'\\b', expanded, text)\n",
    "\n",
    "  text = re.sub(r'\\b\\w\\b', '', text)  # Remove single letters\n",
    "  text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n",
    "  text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "  text = re.sub(r'(.)\\1{2,}', r'\\1', text)  # Replace sequences of the same character > 2 with 1 occurrence\n",
    "  text = re.sub(r'(\\w)[^\\w\\s](\\w)', r'\\1\\2', text)  # Remove special characters within words like 'b@ckward' to 'backward'\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3239e061-f2fd-4688-95c6-76274872a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['comment'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4507fee2-826d-4a3b-8cdd-b28c734e80fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                      dalits are lowlives\n",
      "1                     gay people are burden to our society\n",
      "2                                    arabs are not welcome\n",
      "3         am not saying we should actually eliminate he...\n",
      "4                             bananas are for black people\n",
      "                               ...                        \n",
      "41139                       indian culture is so backwards\n",
      "41140    women do not want equality they just want to b...\n",
      "41141                                           fuck covid\n",
      "41142                             this computer is garbage\n",
      "41143                     the only good muslim is dead one\n",
      "Name: clean_text, Length: 41108, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a0295-7b57-46b8-a2f1-2a3495c3a31e",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86b099-09c4-47ae-98ee-bc0f44f0f932",
   "metadata": {},
   "source": [
    "Tokenization is a way of separating a piece of text into smaller units called tokens. Here, tokens can be either words, characters, or subwords.For example, tokenizing the sentence “I love ice cream” would result in three tokens: “I,” “love,” and “ice cream.” It’s a fundamental step in natural language processing and text analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dddc23ea-a75e-47fa-a504-fd822f191bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data['tokens'] = data['clean_text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "566a08ff-1e93-4cb0-a4fb-9d59d5c4fa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  [dalits, are, lowlives]\n",
       "1             [gay, people, are, burden, to, our, society]\n",
       "2                               [arabs, are, not, welcome]\n",
       "3        [am, not, saying, we, should, actually, elimin...\n",
       "4                       [bananas, are, for, black, people]\n",
       "                               ...                        \n",
       "41139                 [indian, culture, is, so, backwards]\n",
       "41140    [women, do, not, want, equality, they, just, w...\n",
       "41141                                        [fuck, covid]\n",
       "41142                        [this, computer, is, garbage]\n",
       "41143             [the, only, good, muslim, is, dead, one]\n",
       "Name: tokens, Length: 41108, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9b7dc2-4ba6-4234-87ca-d0dfbe0b9d9b",
   "metadata": {},
   "source": [
    "# Stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e959627-4503-4ff2-bc02-771b9916e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "646fe832-46d7-48d5-8284-10ed49b09ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stop words\n",
    "def remove_stop_words(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67f0463f-78cc-4f90-b073-7787660594a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['remove_stopwords'] = data['tokens'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a845908-738e-44fb-ae0e-d8d207e79f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       [dalits, lowlives]\n",
       "1                           [gay, people, burden, society]\n",
       "2                                         [arabs, welcome]\n",
       "3        [saying, actually, eliminate, heebs, wish, nat...\n",
       "4                                 [bananas, black, people]\n",
       "                               ...                        \n",
       "41139                         [indian, culture, backwards]\n",
       "41140                [women, want, equality, want, charge]\n",
       "41141                                        [fuck, covid]\n",
       "41142                                  [computer, garbage]\n",
       "41143                            [good, muslim, dead, one]\n",
       "Name: remove_stopwords, Length: 41108, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['remove_stopwords']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4154b215-b53c-4de3-b626-719aede23c73",
   "metadata": {},
   "source": [
    "# stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9798a72a-b17d-42af-a4f5-ff85aaf77d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "ps= PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac55a1e4-2357-41ca-b3fe-49fa3e2cd642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform stemming\n",
    "def perform_stemming(tokens):\n",
    "    return [ps.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a48c6c54-88a9-4b65-bbfd-0b8e957842d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stemmed'] = data['remove_stopwords'].apply(perform_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50f2ef53-9801-4d9f-a97b-7804cd011e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          [dalit, lowliv]\n",
       "1                            [gay, peopl, burden, societi]\n",
       "2                                           [arab, welcom]\n",
       "3        [say, actual, elimin, heeb, wish, natur, becam...\n",
       "4                                   [banana, black, peopl]\n",
       "                               ...                        \n",
       "41139                           [indian, cultur, backward]\n",
       "41140                    [women, want, equal, want, charg]\n",
       "41141                                        [fuck, covid]\n",
       "41142                                     [comput, garbag]\n",
       "41143                            [good, muslim, dead, one]\n",
       "Name: stemmed, Length: 41108, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stemmed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993ee70-4932-4842-b112-ed663882627a",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d59e41-3a1a-42ea-90b5-38a80538e130",
   "metadata": {},
   "source": [
    "Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context to the words. So, it links words with similar meanings to one word. The practical distinction between stemming and lemmatization is that, where stemming merely removes common suffixes from the end of word tokens, lemmatization ensures the output word is an existing normalized form of the word (for example, lemma) that can be found in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d455e32d-2289-4a91-b443-9f48b85c5812",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2afe0f62-eb67-41ed-9ffc-0cacc0b25e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform lemmatization\n",
    "def perform_lemmatization(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15a30982-a2e8-4c68-b4d5-17813dfac1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemmatized'] = data['remove_stopwords'].apply(perform_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b298bc0c-6239-42a9-b921-9c8255d37a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       [dalits, lowlives]\n",
       "1                           [gay, people, burden, society]\n",
       "2                                          [arab, welcome]\n",
       "3        [saying, actually, eliminate, heebs, wish, nat...\n",
       "4                                  [banana, black, people]\n",
       "                               ...                        \n",
       "41139                         [indian, culture, backwards]\n",
       "41140                [woman, want, equality, want, charge]\n",
       "41141                                        [fuck, covid]\n",
       "41142                                  [computer, garbage]\n",
       "41143                            [good, muslim, dead, one]\n",
       "Name: lemmatized, Length: 41108, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemmatized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3591725-da2e-4637-aa6c-58e7de0f4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data['label_encoded'] = label_encoder.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "562a9374-7f55-435c-aeef-549c23a0c3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved\n"
     ]
    }
   ],
   "source": [
    "data.to_csv('label_encoded.csv', index=False)\n",
    "print(\"File saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b434fa80-5248-4774-9bf6-acdad0e20ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
